\documentclass[runningheads]{llncs}

\begin{document}

\title{AGI and the Knight-Darwin Law}

\author{Samuel Allen Alexander\inst{1}\orcidID{0000-0002-7930-110X}}
\authorrunning{S.\ A.\ Alexander}
\institute{The U.S.\ Securities and Exchange Commission
\email{samuelallenalexander@gmail.com}
\url{https://philpeople.org/profiles/samuel-alexander/publications}}

\maketitle

\begin{abstract}
Fill this in.

\keywords{Fill  \and these \and in.}
\end{abstract}

\section{Introduction}

One of the things that distinguishes AGIs from weaker AIs is that a truly
strong AGI ought to be capable of programming AGIs. After all, an AGI
presumably cannot form spontaneously out of thin air; the first AGI will,
apparently, need to be programmed by humans; but if AGIs are capable of
reasoning and exercising creativity like humans, and if humans are capable
of building AGIs, then AGIs must be capable of building AGIs.

The notion of AGIs programming AGIs is difficult to reason about. In order
to have something solid to put our fingers on, we have attempted to abstract
the core essence of that notion. This led us to discover
what we call the \emph{Literal Ordinal Notation System} (introduced in Section
\ref{notationsystemsection}), an ordinal notation system that gets directly at
the heart of the notion of computer programs writing computer programs.

Say that an AGI is \emph{truthful} if the things it knows are all true,
i.e., if it does not know any falsehoods.
In \cite{alexander2019measuring}, we used the Literal Ordinal Notation System to give an
argument
that it is impossible for a truthful AGI $X$ to create a
truthful AGI $Y$ in such a way that $X$ knows $Y$ is truthful
and such that $Y$ is at least as intelligent as $X$.
The argument is based on the key assumption that if $X$ creates $Y$, then $X$
knows $Y$'s sourcecode.

At first glance, the above impossibility result would
seem to suggest the impossibility of the singularity--the impossibility of
what \cite{hutter2012} refers to as \emph{knowledge explosion}, the idea of
AGIs creating even better AGIs, which create even better AGIs, and so on.
But there is a loophole. Suppose $X$ and $X'$ are two AGIs
who collaborate to create $Y$. Suppose $X$ contributes proprietary sourcecode for
part of $Y$, but keeps it secret from $X'$, and suppose $X'$ contributes proprietary
sorcecode for another part of $Y$, but keeps it secret from $X$. Then neither
$X$ nor $X'$ knows the full sourcecode of $Y$, and the argument for the
above-mentioned impossibility result breaks down.

The above-mentioned impossibility result would imply that if truthful
AGI $X$ creates (without any outside
help) truthful AGI $Y$, and knows the truthfulness and the sourcecode of $Y$,
then $Y$ is less intelligent than $X$. In particular, suppose $X_1,X_2,\ldots$
are truthful AGIs such that each $X_i$ creates, and knows the truthfulness and
the sourcecode of, $X_{i+1}$. Then by applying the impossibility result repeatedly,
it would follow that $X_1$ must be more intelligent than $X_2$, which must be more
intelligent than $X_3$, and so on forever. If intelligence is well-founded (i.e.,
if it is impossible for there to be an infinite sequence of AGIs, each one more
intelligent than the next), then this would imply that it is impossible for such
a list $X_1,X_2,\ldots$ to go on forever: it would have to stop after finitely
many elements. But the above loophole offers a way that the list could go on
forever, namely: if, for certain values of $i$, $X_i$ did not create $X_{i+1}$
without outside help, but relied on a collaborator $X'_i$ (so that $X_i$ would
not fully know the sourcecode of $X_{i+1}$).

The Knight-Darwin law, named after Charles Darwin and Andrew Knight, is the
principal (rephrased in modern language) that there cannot be an infinite
sequence $X_1,X_2,\ldots$ of biological organisms such that each $X_i$ asexually
parents $X_{i+1}$. In other words, if $X_1,X_2,\ldots$ is any infinite list of
organisms such that each $X_i$ is a biological parent of $X_{i+1}$, then there
would necessarily have to be certain values of $i$ such that
$X_i$ parents $X_{i+1}$ sexually with together with a co-parent $X'_{i}$.
The reader will immediately notice a striking parallel between
this principal and the discussion in the previous paragraph.

In Section \ref{notationsystemsection} we introduce the Literal Ordinal Notation
System.

In Section \ref{informalargumentsection} we give an informal version of the
argument that if a truthful AGI $X$ creates a truthful AGI $Y$, such that $X$
knows the truthfulness and the sourcecode of $Y$, then $Y$ is less intelligent
than $X$.

In Section \ref{kdlawsection} we review the Knight-Darwin Law from biology.

In Section \ref{knightdarwinagisection} we adapt the Knight-Darwin Law to AGI
and speculate about what it might mean for AGI, including implications about
the creation of AGI.


\section{The Literal Ordinal Notation System}
\label{notationsystemsection}

\section{An Informal Version of the Impossibility Argument}
\label{informalargumentsection}

\section{The Knight-Darwin Law}
\label{kdlawsection}

\section{The Knight-Darwin Law for AGI}
\label{knightdarwinagisection}


\bibliographystyle{splncs04}
\bibliography{agikd}

\end{document}