\documentclass[runningheads]{llncs}

\begin{document}

\title{AGI and the Knight-Darwin Law}

\author{Samuel Allen Alexander\inst{1}\orcidID{0000-0002-7930-110X}}
\authorrunning{S.\ A.\ Alexander}
\institute{The U.S.\ Securities and Exchange Commission
\email{samuelallenalexander@gmail.com}
\url{https://philpeople.org/profiles/samuel-alexander/publications}}

\maketitle

\begin{abstract}
Fill this in.

\keywords{Fill \and these \and in.}
\end{abstract}

\section{Introduction}

One of the things that distinguishes AGIs from weaker AIs is that a truly
strong AGI ought to be capable of programming AGIs. After all, an AGI
presumably cannot form spontaneously out of thin air; the first AGI will,
apparently, need to be programmed by humans; but if AGIs are capable of
reasoning and exercising creativity like humans, and if humans are capable
of building AGIs, then AGIs must be capable of building AGIs.

The notion of AGIs programming AGIs is difficult to reason about. In order
to have something solid to put our fingers on, we have attempted to abstract
the core essence of that notion. This led us to discover
what we call the \emph{Literal Ordinal Notation System} (introduced in Section
\ref{notationsystemsection}), an ordinal notation system that gets directly at
the heart of the notion of computer programs writing computer programs.

Say that an AGI is \emph{truthful} if the things it knows are all true,
i.e., if it does not know any falsehoods.
In \cite{alexander2019measuring}, we used the Literal Ordinal Notation System to give an
argument
that it is impossible for a truthful AGI $X$ to create a
truthful AGI $Y$ in such a way that $X$ knows $Y$ is truthful
and such that $Y$ is at least as intelligent as $X$.
The argument is based on the key assumption that if $X$ creates $Y$, then $X$
knows $Y$'s sourcecode.

At first glance, the above impossibility result would
seem to suggest the impossibility of the singularity--the impossibility of
what \cite{hutter2012} refers to as \emph{knowledge explosion}, the idea of
AGIs creating even better AGIs, which create even better AGIs, and so on.
But there is a loophole. Suppose $X$ and $X'$ are two AGIs
who collaborate to create $Y$. Suppose $X$ contributes proprietary sourcecode for
part of $Y$, but keeps it secret from $X'$, and suppose $X'$ contributes proprietary
sorcecode for another part of $Y$, but keeps it secret from $X$. Then neither
$X$ nor $X'$ knows the full sourcecode of $Y$, and the argument for the
above-mentioned impossibility result breaks down.

The above-mentioned impossibility result would imply that if truthful
AGI $X$ creates (without any outside
help) truthful AGI $Y$, and knows the truthfulness and the sourcecode of $Y$,
then $Y$ is less intelligent than $X$. In particular, suppose $X_1,X_2,\ldots$
are truthful AGIs such that each $X_i$ creates, and knows the truthfulness and
the sourcecode of, $X_{i+1}$. Then by applying the impossibility result repeatedly,
it would follow that $X_1$ must be more intelligent than $X_2$, which must be more
intelligent than $X_3$, and so on forever. If intelligence is well-founded (i.e.,
if it is impossible for there to be an infinite sequence of AGIs, each one more
intelligent than the next), then this would imply that it is impossible for such
a list $X_1,X_2,\ldots$ to go on forever: it would have to stop after finitely
many elements. But the above loophole offers a way that the list could go on
forever, namely: if, for certain values of $i$, $X_i$ did not create $X_{i+1}$
without outside help, but relied on a collaborator $X'_i$ (so that $X_i$ would
not fully know the sourcecode of $X_{i+1}$).

The Knight-Darwin law \cite{darwin1898knight}, named after Charles Darwin
and Andrew Knight, is the
principal (rephrased in modern language) that there cannot be an infinite
sequence $X_1,X_2,\ldots$ of biological organisms such that each $X_i$ asexually
parents $X_{i+1}$. In other words, if $X_1,X_2,\ldots$ is any infinite list of
organisms such that each $X_i$ is a biological parent of $X_{i+1}$, then there
would necessarily have to be certain values of $i$ such that
$X_i$ parents $X_{i+1}$ sexually with together with a co-parent $X'_{i}$.
The reader will immediately notice a striking parallel between
this principal and the discussion in the previous paragraph.

In Section \ref{notationsystemsection} we introduce the Literal Ordinal Notation
System.

In Section \ref{informalargumentsection} we give an informal version of the
argument that if a truthful AGI $X$ creates a truthful AGI $Y$, such that $X$
knows the truthfulness and the sourcecode of $Y$, then $Y$ is less intelligent
than $X$.

In Section \ref{kdlawsection} we review the Knight-Darwin Law from biology.

In Section \ref{knightdarwinagisection} we adapt the Knight-Darwin Law to AGI
and speculate about what it might mean for AGI, including implications about
the creation of AGI.


\section{The Literal Ordinal Notation System}
\label{notationsystemsection}

We do not know what, exactly, an AGI is, but we want to study AGIs anyway.
Based on the conviction that an AGI should be capable of programming AGIs,
we would like to come up with a more concrete kind of structure, easier to reason
about, which we can use as a proxy for AGIs.

What sort of structure would capture the essence of an AGI's capability
of programming AGI's? As an initial attempt, how about this: ``computer
program that outputs computer programs''? That seems like the right direction
to go, but as written, there is no constraint on the computer programs which
are outputted, so this initial attempt seems to capture the essence of an
AGI's capability of writing \emph{computer programs}, not the essence of an
AGI's capability of writing \emph{AGIs}.

As a second attempt, how
about this: ``computer program that outputs computer programs that output
computer programs''? This brings us a little closer, but this second attempt
seems to capture the essence of an AGI's capability of writing \emph{first-attempt programs},
rather than the essence of an AGI's capability of writing \emph{AGIs}.

As a third attempt, how about this:
``computer program that outputs computer programs that output computer programs
that output computer programs''? This brings us closer still, but this third
attempt seems to capture the essence of an AGI's capability of writing
\emph{second-attempt programs}, rather than the essence of an AGI's capability of
writing \emph{AGIs}.

It seems like we need to short-circuit this process. We need to come up with a notion
X which is equivalent to ``computer program that outputs members of X''.
Fortunately, this is not difficult to do using a basic trick from mathematics.
We will fill in the blank X sign with the phrase ``Literal Ordinal Notation''.

\begin{definition}
\label{literalnotationdef}
    (See the following examples)
    We define the Literal Ordinal Notations to be the smallest set $\mathcal P$
    satisfying the following properties:
    \begin{enumerate}
        \item
            Every element of $\mathcal P$ is a computer program.
        \item
            For every computer program $p$,
            if $\mathcal P$ contains every output that gets printed when $p$ is executed,
            then $p\in\mathcal P$.
    \end{enumerate}
\end{definition}

\begin{example}
\label{simpleexamples}
(Some simple examples)
    \begin{itemize}
    \item
    Let $P_0$ be ``End'', a program which immediately stops without printing any outputs.
    Vacuously, every output $x$ that gets printed when $P_0$ is executed is in $\mathcal P$
    (because there are no such outputs). So by condition 2 of
    Definition \ref{literalnotationdef}, $P_0$ is a Literal Ordinal Notation.
    \item
    Let $P_1$ be ``Print(``End'')'', a program which prints the output ``End'' and then
    stops. We already saw $\mbox{``End''}\in\mathcal P$, so by condition 2 of
    Definition \ref{literalnotationdef}, $P_1$ is a Literal Ordinal Notation.
    \item
    Let $P_2$ be ``Print(``Print(``End'')'')'', which prints ``Print(``End'')'' and then
    stops. We already saw $\mbox{``Print(``End'')''}\in\mathcal P$, so by condition 2
    of Definition \ref{literalnotationdef}, $P_2$ is a Literal Ordinal Notation.
    \end{itemize}
\end{example}

\begin{example}
\label{omegaexample}
(A more interesting example)
    Let $P_\omega$ be the program:
    \[
        \mbox{Let X = `End'; While(True) \{ Print(X); X = ``Print(`'' + X + ``')''; \}}
    \]
    When executed, $P_\omega$ prints ``End'', ``Print(``End'')'',
    ``Print(``Print(``End'')'')'', and so on forever. By similar reasoning as
    in Example \ref{simpleexamples}, all of these are Literal Ordinal Notations.
    Therefore, $P_\omega$ is a Literal Ordinal Notation.
\end{example}

Because of the recursive way the Literal Ordinal Notations are defined, there is a
natural way to assign computable ordinal numbers to them. This is why we call them
Literal Ordinal Notations--we think of each Literal Ordinal Notation as notating
(that is, as being a name for) the computable ordinal number assigned to it.
How do we assign a computable ordinal to a Literal Ordinal Notation $x$? Well, because
of the recursive nature of the definition, we can assume (by induction) that we've
already assigned computable ordinals to all the outputs which are printed when $x$
is executed (this makes sense because all such outputs are Literal Ordinal Notations,
by definition). So the answer is clear: assign $x$ the first computable ordinal bigger
than all the computable ordinals assigned to the outputs of $x$.

\begin{definition}
    For any Literal Ordinal Notation $x$, we define a computable ordinal $|x|$
    inductively as follows: $|x|$ is the smallest computable ordinal $\alpha$
    such that $\alpha>|y|$ for every output $y$ that gets printed when $x$ is
    executed.
\end{definition}

\begin{example}
    \begin{enumerate}
        \item
        Since $P_0$ (from Example \ref{simpleexamples}) has no outputs,
        it follows that $|P_0|=0$, the smallest computable ordinal.
        \item
        Likewise, $|P_1|=1$ and $|P_2|=2$.
        \item
        Likewise, $P_\omega$ (from Example \ref{omegaexample}) has outputs
        notating $0, 1, 2, \ldots$---all the finite natural numbers---and no
        other outputs. It follows that $|P_\omega|=\omega$, the smallest
        infinite ordinal number.
        \item
        Let $P_{\omega+1}$ be the program ``Print($P_\omega$)'',
        where $P_\omega$ is as in Example \ref{omegaexample}.
        It follows that $|P_{\omega+1}|=\omega+1$, the next ordinal after
        $\omega$.
    \end{enumerate}
\end{example}

The Literal Ordinal Notation System is similar to Kleene's $\mathcal O$,
an ordinal notation system devised by Stephen Kleene \cite{kleene}.

\section{An Informal Version of the Impossibility Argument}
\label{informalargumentsection}

Whatever an AGI is, presumably an AGI knows certain mathematical facts
(or could eventually deduce them, if placed in an isolated room for all eternity).
The following definition offers a way to quantify an AGI's intelligence based
solely on the mathematical facts that the AGI knows. In \cite{alexander2019measuring}
we champion this as an appropriate intelligence measure by arguing that it
captures key components of intelligence such as pattern recognition, creativity, and
the ability to abstract and to generalize.
% In the present paper, we'll add the
% following observations to further justify the definition. In some sense, any
% quantifiable measurement

\begin{definition}
\label{maindefinition}
    The \emph{Literal Ordinal Intelligence} of an AGI $X$ is the smallest computable
    ordinal $\alpha$ such that $\alpha>|p|$ for every Literal Ordinal Notation
    $p$ such that $X$ knows (or would eventually figure out) that $p$ is a
    Literal Ordinal Notation.
\end{definition}

Armed with Definition \ref{maindefinition}, we will give an informal version of the
impossibility result from the Introduction.

\begin{theorem}
\label{maintheorem}
    Suppose $X$ is a truthful AGI, and $X$ creates a truthful AGI $Y$.
    Assume $X$ knows $Y$'s sourcecode, and that $X$ knows that $Y$ is truthful.
    Then $X$'s Literal Ordinal Intelligence is strictly greater than $Y$'s
    Literal Ordinal Intelligence.
\end{theorem}

\begin{proof}
    Suppose $Y$ were isolated for all eternity with just one instruction:
    to spend eternity enumerating the biggest Literal Ordinal Notations $Y$ could
    think of. This would result in some list $L$ of Literal Ordinal Notations
    enumerated by $Y$. Since $Y$ is an AGI, $L$ must be computable, because $L$ can
    be enumerated by a robot (namely by $Y$). Thus, there is some computer program
    $P$ which outputs exactly the list $L$. Since $X$ knows $Y$'s sourcecode,
    and presumably $X$ is capable of elementary reasoning about sourcecodes and
    how to manipulate sourcecodes, it follows that $X$ can infer $P$--that is to
    say, $X$ knows (or would eventually figure out) the statement, ``$P$ outputs
    $L$, the list of things $Y$ would enumerate if $Y$ went off to enumerate
    Literal Ordinal Notations for all eternity''. Since $X$ knows $Y$ is truthful,
    $X$ can deduce that $L$ contains nothing except Literal Ordinal Notations,
    and thus $X$ can deduce that all the outputs of $P$ are Literal Ordinal Notations,
    and so $X$ knows (or would eventually figure out) that $P$ is a Literal Ordinal Notation.
    Clearly $P$ notates an ordinal bigger than the ordinals notated by anything in $L$,
    so since $X$ knows $P$ is a Literal Ordinal Notation, it follows $X$ has a larger
    Literal Ordinal Intelligence than $Y$.
\end{proof}

\section{The Knight-Darwin Law}
\label{kdlawsection}

\begin{quote}
``...it is a general law of nature that no organic being self-fertilises itself
for a perpetuity of generations; but that a cross with another individual
is occasionally---perhaps at long intervals of time---indispensable.''
(Charles Darwin)
\end{quote}

In his Origin of Species \cite{originofspecies}, Charles Darwin devotes many
pages to the above-quoted principal, which would later become known as the
Knight-Darwin Law \cite{darwin1898knight}. In \cite{alexander2013} and
\cite{alexander2015}, based on a close reading of Darwin's text, we argue
that the Knight-Darwin Law is accurately translated into modern mathematical
language as follows.

\begin{principle}
(The Knight-Darwin Law)
It is impossible for there to be an infinite sequence
$x_1,x_2,\ldots$ of living organisms such that each $x_i$
is the lone biological parent of $x_{i+1}$. In other words,
if there are ever organisms $x_1,x_2,\ldots$ such that each
$x_i$ is a biological parent of $x_{i+1}$, then there must
be some $i>1$ such that $x_i$ has multiple distinct biological
parents.
\end{principle}


\section{The Knight-Darwin Law for AGI}
\label{knightdarwinagisection}

One of the most important properties of the ordinal numbers is the
fact that they are \emph{well-founded}: by which we mean, there is
no infinite sequence $o_1,o_2,\ldots$ of ordinals such that each
$o_i>o_{i+1}$. In Theorem \ref{maintheorem} we showed that if truthful
AGI $X$ creates truthful AGI $Y$, and if $X$ knows the truthfulness
and the sourcecode of $Y$, then $X$ has a higher Literal Ordinal Intelligence
than $Y$. Combining this with the well-foundedness of the ordinals yields
a theorem which is extremely similar to the Knight-Darwin Law.

\begin{theorem}
(The Knight-Darwin Law for AGIs)
It is impossible for there to be an infinite sequence
$x_1,x_2,\ldots$ of truthful AGIs such that each $x_i$ is the lone creator of $x_{i+1}$.
In other words, if there are
ever truthful AGIs $x_1,x_2,\ldots$ such that each $x_i$ is a creator of $x_{i+1}$,
then there must be some $i>1$ such that multiple distinct creators collaborated to
create $x_i$.
\end{theorem}

\begin{proof}
By contradiction. Assume $x_1,x_2,\ldots$ is an infinite sequence of truthful AGIs such
that each $x_i$ is the lone creator of $x_{i+1}$. For each $i$, let $\alpha_i$
be the Literal Ordinal Intelligence of $x_i$. By Theorem \ref{maintheorem},
$\alpha_1>\alpha_2>\cdots$. This contradicts the well-foundedness of the ordinal
numbers.
\end{proof}


\bibliographystyle{splncs04}
\bibliography{agikd}

\end{document}